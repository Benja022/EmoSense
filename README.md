
# ğŸ“¢ EmoSense

## 1ï¸âƒ£ Introduction  
In a society where emotional intelligence, mental health, and emotional states are increasingly important, companies need to adapt to improve user experience and customer loyalty. ğŸ’¡ğŸ’–  

EmoSense is a Machine Learning-based application ğŸ¤– that detects emotions through communication channels, both verbal and written. It analyzes:  
- ğŸµ **Audio waves and spectrograms**.  
- ğŸ“ **The semantic meaning of words**.  

## 2ï¸âƒ£ Problem Statement  
Companies with a large number of customers (âœˆï¸ airlines, ğŸš† trains, ğŸ›’ large-scale sales) seek to **automate** customer service without losing quality. Many users are still reluctant to interact with machines. ğŸ¤¯  

By adding **emotion analysis** to these automated methods, we can **enhance the experience** and **increase customer loyalty**. ğŸ¯ğŸ˜Š  

## 3ï¸âƒ£ Estado Actual

En nuestra investigaciÃ³n encontramos dos enfoques:

1. ğŸ“œ **AnÃ¡lisis semÃ¡ntico**: Speech-to-text para convertir audio en texto y analizar las palabras.
2. ğŸ™ï¸ **AnÃ¡lisis de audio**: Ondas, tono y espectrogramas para deducir emociones.

### ğŸ§  Algoritmos encontrados

- Modelos tradicionales: ğŸŒ² Random Forest, ğŸŒ³ Decision Tree.
- Modelos avanzados: ğŸ¤– Deep Neural Networks (DNNs), ğŸ§© Convolutional Neural Networks (CNNs).
## 3ï¸âƒ£ Current State  
In our research, we found two approaches:  
1. ğŸ“œ **Semantic analysis**: Speech-to-text to convert audio into text and analyze the words.  
2. ğŸ™ï¸ **Audio analysis**: Waves, tone, and spectrograms to deduce emotions.  

### ğŸ§  Algorithms Found  
- Traditional models: ğŸŒ² Random Forest, ğŸŒ³ Decision Tree.  
- Advanced models: ğŸ¤– Deep Neural Networks (DNNs), ğŸ§© Convolutional Neural Networks (CNNs).  

For our application, we will test various models and select the most suitable one. âš™ï¸ğŸ“Š  

## 4ï¸âƒ£ Methodology  
### ğŸ“‚ Data Source  
ğŸ“Œ **RAVDESS Emotional Speech Audio**  
ğŸ”— [Dataset on Kaggle](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)  

The emotions are labeled in the filenames:  
- ğŸ˜ Neutral (01)  
- ğŸ˜Œ Calm (02)  
- ğŸ˜ƒ Happy (03)  
- ğŸ˜¢ Sad (04)  
- ğŸ˜¡ Angry (05)  
- ğŸ˜¨ Fearful (06)  
- ğŸ¤¢ Disgusted (07)  
- ğŸ˜² Surprised (08)  

Other characteristics such as **intensity and actor** are also included. ğŸ­  

### ğŸ” Preprocesamiento de Datos

- ğŸ“Œ Limpieza y normalizaciÃ³n.
- ğŸ“ˆ Aumento de datos (Data Augmentation).

### âš™ï¸ Modelo de Machine Learning

- Algoritmos utilizados: ğŸ§  CNN, RNN, Transformers.
- Arquitectura del modelo: ğŸ”„ Capas, funciones de activaciÃ³n, etc.
- Herramientas y frameworks: ğŸ› ï¸ TensorFlow, PyTorch, Scikit-Learn.

### ğŸ¯ Entrenamiento y ValidaciÃ³n

- DivisiÃ³n de datos: ğŸ“Š Train / Validation / Test.
- MÃ©tricas de evaluaciÃ³n: ğŸ¯ PrecisiÃ³n, Recall, F1-score.
- Mejora del rendimiento: ğŸ”„ Data Augmentation, Transfer Learning, RegularizaciÃ³n.

## 5ï¸âƒ£ Resultados ğŸ“Š

- ğŸ“ˆ DesempeÃ±o del modelo en pruebas.
- âš–ï¸ ComparaciÃ³n con otros enfoques.
- ğŸ” Ejemplos de predicciones correctas e incorrectas.

## 6ï¸âƒ£ Conclusiones y Futuro Trabajo ğŸš€

- ğŸ” **Hallazgos**: Â¿QuÃ© hemos aprendido?
- âš ï¸ **Limitaciones**: Â¿QuÃ© dificultades encontramos?
- ğŸ› ï¸ **Mejoras futuras**: ExpansiÃ³n del dataset, optimizaciÃ³n del modelo, implementaciÃ³n en producciÃ³n.

## 7ï¸âƒ£ Referencias ğŸ“š

### ğŸ” Data Preprocessing  
- ğŸ“Œ Cleaning and normalization.  
- ğŸ“ˆ Data augmentation.  

### âš™ï¸ Machine Learning Model  
- Algorithms used: ğŸ§  MLP, SVM, CNN.  
- Tools and frameworks: ğŸ› ï¸ TensorFlow, Librosa, Scikit-Learn.  

### ğŸ¯ Training and Validation  
- Data split: ğŸ“Š Train / Validation / Test.  
- Evaluation metrics: ğŸ¯ Accuracy, Confusion Matrix.  
- Performance improvement: ğŸ”„ Class rebalancing with SMOTE, Model optimization with GridSearch.  

## 5ï¸âƒ£ Results ğŸ“Š  
- A Streamlit app that predicts emotions after recording an audio or writing a sentence.  

## 6ï¸âƒ£ Conclusions and Future Work ğŸš€  
- Text-based emotion recognition has proven to be highly effective.  
- Audio-based emotion recognition presents unique challenges (finding datasets in Spanish, long training time, data quality).  
- In the weighting of the emotion decision, the prediction with text has more influence.  

## 6ï¸âƒ£ Future Improvements ğŸš€  
- Expand training data to Spanish audio.  
- Integrate English text-based emotion recognition.  
- Real-time feedback loop for model improvement.  
- Data augmentation to enhance the model.  
- More emotions.  
- The emotion decision will be weighted by the model's accuracy.  

## 7ï¸âƒ£ References ğŸ“š  

ğŸ“– **Implementing Machine Learning Techniques for Continuous Emotion Prediction from Uniformly Segmented Voice Recordings**
ğŸ”— [ArtÃ­culo en Frontiers in Psychology](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1300996/full)

## ğŸ’» Run the streamlit app

Yo have two options to run the app:

1. If you have streamlit installed. Run the app with the following steps:

    1.1. Go to `streamlit-app/src` folder.

    1.2. Run the following command:

    ```bash
    streamlit run app.py
    ```

2. Run the app with docker:

    2.1. Go to `streamlit-app` folder and run the following command:
    docker build -t streamlit-app .
    2.2. Run the docker container with the following command:

```bash
docker run -p 8501:8501 streamlit-app
```

Then you can access the app at [http://localhost:8501](http://localhost:8501).

In `streamlit-app/src` folder you can find the `app.py` file where the app is defined to run with streamlit in your local machine. And `app2.py` file where the app is defined to run with docker.
